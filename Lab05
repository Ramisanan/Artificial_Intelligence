# CSE422
import pandas as pd
import numpy as np
import sympy as sp
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

mushroom_classification = pd.read_csv('/mushroom edibility classification dataset.csv')
mushroom_classification.head(5)

mushroom_classification['class'].unique()
mushroom_classification['bruises'].unique()

#encoding
enc = LabelEncoder()
mushroom_classification['class'] = enc.fit_transform(mushroom_classification['class'])
mushroom_classification['bruises'] = enc.fit_transform(mushroom_classification['bruises'])


mushroom_classification.isnull().sum()

# dropping unnecessary column and row
mushroom_classification = mushroom_classification.dropna(axis=0, subset=['cap-shape', 'cap-color'])
mushroom_classification = mushroom_classification.drop(['veil-type'], axis=1)

mushroom_classification = mushroom_classification.drop(['stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring'], axis=1)
Mushroom_classification.shape

mushroom_classification_cor = mushroom_classification.corr()

from sklearn.preprocessing import MinMaxScaler
scale = MinMaxScaler()
scale.fit(mushroom_classification)
scale = scale.transform(mushroom_classification)
scale

from sklearn.model_selection import train_test_split
an = pd.DataFrame(mushroom_classification['class'])
x_train, x_test, y_train, y_test = train_test_split(mushroom_classification, mushroom_classification['class'], test_size=0.2, random_state=42, stratify=an)

x = mushroom_classification.iloc[:,1:13]
y = mushroom_classification.iloc[:, 1]


model = LogisticRegression()
model.fit(x_train, y_train)   
predictions = model.predict(x_test)
print(predictions)  

score1=accuracy_score(y_test, predictions)
print(score1)

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=100)
clf = DecisionTreeClassifier(criterion='entropy',random_state=100)
clf.fit(x_train,y_train)
y_pred = clf.predict(x_test)
score=accuracy_score(y_pred,y_test)
print(score)

from sklearn import tree
import matplotlib.pyplot as plt
import matplotlib
fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (6,6), dpi=100)
tree.plot_tree(clf, feature_names = x.columns, class_names=['1','2','3','4','5','6','7'], filled = True)

objects = ('Logistic Regression', 'Decision Tree')
y_pos = np.arange(len(objects))
performance = [score1 * 100, score * 100]
width = 0.5

fig,ax=plt.subplots(figsize=(7, 10))
rects1 = ax.bar(y_pos, performance,alpha=0.5)
ax.set_ylabel('Accuracy Scores %')
ax.set_title('Scores by two different methods')
ax.set_xticks(y_pos)
ax.set_yticks(np.arange(0, 100, 5))
ax.set_xticklabels(objects)

autolabel(rects1)
fig.tight_layout()
plt.show()
